{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1721977-232d-466f-86f1-ce7817c4a2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SWAPNIL\\anaconda\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ed40f4-91de-4ed4-8004-735cf9bb2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/synthetic_logs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee9cfb5-f3fc-493f-813f-e5842986c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_regex(log_message):\n",
    "    regex_patterns = {\n",
    "        r\"User User\\d+ logged (in|out).\": \"User Action\",\n",
    "        r\"Backup (started|ended) at .*\": \"System Notification\",\n",
    "        r\"Backup completed successfully.\": \"System Notification\",\n",
    "        r\"System updated to version .*\": \"System Notification\",\n",
    "        r\"File .* uploaded successfully by user .*\": \"System Notification\",\n",
    "        r\"Disk cleanup completed successfully.\": \"System Notification\",\n",
    "        r\"System reboot initiated by user .*\": \"System Notification\",\n",
    "        r\"Account with ID .* created by .*\": \"User Action\"\n",
    "    }\n",
    "    for pattern, label in regex_patterns.items():\n",
    "        if re.search(pattern, log_message, re.IGNORECASE):\n",
    "            return label\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0f4f5e4-0378-49f4-815a-48f4ccdcb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['regex_label'] = df['log_message'].apply(classify_with_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d152e681-9a07-491d-bcb0-c9f36a7ef3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate regex matches (high confidence)\n",
    "df_regex = df[df['regex_label'].notnull()]\n",
    "df_non_regex = df[df['regex_label'].isnull()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c24235-e425-4cb7-b8a7-6aa903172761",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_regex = df_non_regex[df_non_regex.source != 'LegacyCRM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "120fd542-9550-489b-8cec-6323f45bcd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_log(log):\n",
    "    log = re.sub(r\"\\bUser\\d+\\b\", \"USER_ID\", log)\n",
    "    log = re.sub(r\"\\b\\d{4}-\\d{2}-\\d{2}\\b\", \"DATE\", log)\n",
    "    log = re.sub(r\"\\b\\d+\\.\\d+\\.\\d+\\.\\d+\\b\", \"IP_ADDR\", log)\n",
    "    log = re.sub(r\"\\b\\d+\\b\", \"NUM\", log)\n",
    "    return log.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ac6fdf-9c2f-45e0-a0b4-55252dad04e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_regex['normalized_message'] = df_non_regex['log_message'].apply(normalize_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c8648b-6699-401c-819e-713aa7550859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e65df853e24cf4986256028f26024d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(df_non_regex['normalized_message'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad685476-d29e-4615-8ecf-070a8b8e6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.2, min_samples=1, metric='cosine')\n",
    "clusters = dbscan.fit_predict(embeddings)\n",
    "df_non_regex['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8c850cb-707d-401d-bba5-635630ed1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = df_non_regex['cluster'].value_counts()\n",
    "large_clusters = cluster_counts[cluster_counts > 10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d36c7cc2-5928-4971-b605-2e555a29a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 1 classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Critical Error       1.00      1.00      1.00         6\n",
      "         Error       1.00      1.00      1.00         6\n",
      "\n",
      "      accuracy                           1.00        12\n",
      "     macro avg       1.00      1.00      1.00        12\n",
      "  weighted avg       1.00      1.00      1.00        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "per_cluster_models = {}\n",
    "for cluster_id in large_clusters:\n",
    "    cluster_df = df_non_regex[df_non_regex['cluster'] == cluster_id]\n",
    "    X = model.encode(cluster_df['normalized_message'].tolist())\n",
    "    y = cluster_df['target_label']\n",
    "\n",
    "    if len(set(y)) > 1:  # Avoid single-class clusters\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42\n",
    "        )\n",
    "        clf = LogisticRegression(max_iter=1000)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(f\"\\nCluster {cluster_id} classification report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        per_cluster_models[cluster_id] = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ef83836-adcf-4c10-bbe1-852c291ed22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General classifier report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Critical Error       0.91      1.00      0.95        48\n",
      "         Error       0.98      0.89      0.93        47\n",
      "   HTTP Status       1.00      1.00      1.00       304\n",
      "Resource Usage       1.00      1.00      1.00        49\n",
      "Security Alert       1.00      0.99      1.00       123\n",
      "\n",
      "      accuracy                           0.99       571\n",
      "     macro avg       0.98      0.98      0.98       571\n",
      "  weighted avg       0.99      0.99      0.99       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_all = embeddings\n",
    "y_all = df_non_regex['target_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.3, random_state=42)\n",
    "\n",
    "general_clf = LogisticRegression(max_iter=1000)\n",
    "general_clf.fit(X_train, y_train)\n",
    "y_pred = general_clf.predict(X_test)\n",
    "print(\"\\nGeneral classifier report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc32ff6-ef82-4c6e-b0b5-fdeff8b3cb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/per_cluster_models.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, \"../models/sentence_transformer.pkl\")\n",
    "joblib.dump(general_clf, \"../models/general_logistic_regression.pkl\")\n",
    "joblib.dump(per_cluster_models, \"../models/per_cluster_models.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223a6e1e-087d-42d9-8c9e-931fa03c9f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
